{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8677a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.\n",
    "\n",
    "# Scenarios Where Multithreading is Preferable:\n",
    "\n",
    "# 1. **I/O-Bound Tasks**: \n",
    "#   - **Description**: When tasks spend a significant amount of time waiting for input/output operations, such as reading from disk, network communication, or database access.\n",
    "#   - **Example**: A web server handling multiple requests, where each request involves waiting for data from a database or an external API. Using multithreading allows other threads to continue processing while one thread waits for I/O operations to complete.\n",
    "\n",
    "# 2. **Lightweight Tasks**:\n",
    "#    - **Description**: When the overhead of creating and managing multiple processes is too high, multithreading can be more efficient for lightweight tasks.\n",
    "#    - **Example**: Applications where tasks involve minor computations but many of them need to be executed, like downloading multiple files simultaneously.\n",
    "\n",
    "# 3. **Shared Memory**:\n",
    "#    - **Description**: Multithreading is beneficial when tasks need to share memory or data structures easily, as threads share the same memory space.\n",
    "#    - **Example**: Applications requiring real-time data processing where threads need to access and modify shared data frequently, like a simulation application.\n",
    "\n",
    "# 4. **User Interface (UI) Applications**:\n",
    "#    - **Description**: In applications with graphical user interfaces (GUIs), keeping the UI responsive while performing background tasks is crucial.\n",
    "#    - **Example**: A desktop application where a separate thread handles file downloads while the main thread keeps the user interface responsive.\n",
    "\n",
    "# Scenarios Where Multiprocessing is a Better Choice:\n",
    "\n",
    "# 1. **CPU-Bound Tasks**:\n",
    "#    - **Description**: When tasks require significant CPU resources and involve heavy computations, multiprocessing can take full advantage of multiple CPU cores.\n",
    "#    - **Example**: Scientific computations, data processing, and machine learning model training, where tasks are CPU-intensive and can be executed in parallel without waiting for I/O.\n",
    "\n",
    "# 2. **Isolation**:\n",
    "#    - **Description**: When tasks need to be isolated from one another to prevent issues related to shared state or memory corruption.\n",
    "#    - **Example**: Running untrusted code or tasks that might crash. Each process runs in its own memory space, ensuring that a failure in one process does not affect others.\n",
    "\n",
    "# 3. **Python's Global Interpreter Lock (GIL)**:\n",
    "#    - **Description**: In CPython (the standard Python implementation), the Global Interpreter Lock (GIL) allows only one thread to execute at a time in a single process. This can hinder performance for CPU-bound tasks when using threads.\n",
    "#    - **Example**: For tasks like image processing or mathematical computations, using multiple processes bypasses the GIL and can significantly improve performance.\n",
    "\n",
    "# 4. **Scalability**:\n",
    "#    - **Description**: Multiprocessing can be more scalable, especially in distributed systems or when using cluster computing.\n",
    "#   - **Example**: Data processing pipelines that can distribute workloads across multiple machines or cores, like processing large datasets in a distributed environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075ea189",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Describe what a process pool is and how it helps in managing multiple processes efficiently\n",
    "\n",
    "# A process pool is a collection of pre-initialized worker processes that are managed together to perform tasks concurrently.\n",
    "# It provides a way to manage and control multiple processes more efficiently, avoiding the overhead associated with creating and destroying processes for each task. \n",
    "\n",
    "# Key Concepts of a Process Pool\n",
    "\n",
    "#1. **Worker Processes**:\n",
    "#   - A process pool consists of a fixed number of worker processes that are created at the start. These processes remain alive and are available to execute tasks.\n",
    "#   - Each worker can pick up a task from the pool and execute it independently of others.\n",
    "\n",
    "#2. **Task Submission**:\n",
    "#   - Users submit tasks to the process pool, which are then queued up for execution by the available worker processes.\n",
    "#   - This queuing mechanism helps to manage the distribution of tasks across the workers without overwhelming the system.\n",
    "\n",
    "#3. **Concurrency**:\n",
    "#   - The process pool allows multiple tasks to be executed concurrently by utilizing the available CPU cores effectively.\n",
    "#   - This parallel execution can lead to significant performance improvements, especially for CPU-bound tasks that benefit from parallel processing.\n",
    "\n",
    "# Advantages of Using a Process Pool\n",
    "\n",
    "# 1. **Reduced Overhead**:\n",
    "#   - Creating and destroying processes can be resource-intensive and time-consuming.\n",
    "#   -A process pool eliminates this overhead by reusing existing worker processes for multiple tasks.\n",
    "#   - This leads to faster task execution as workers are readily available when new tasks arrive.\n",
    "\n",
    "#2. **Efficient Resource Management**:\n",
    "#   - By limiting the number of active processes in the pool, resource consumption (such as memory and CPU usage) is managed more effectively.\n",
    "#   - This prevents resource exhaustion and allows the system to maintain stability while handling multiple tasks.\n",
    "\n",
    "#3. **Load Balancing**:\n",
    "#   - The process pool can automatically distribute tasks among the available worker processes, ensuring that no single process is overloaded while others are idle.\n",
    "#   - This load balancing helps optimize the utilization of CPU cores.\n",
    "\n",
    "#4. **Simplified Code**:\n",
    "#   - Using a process pool abstracts away the complexities of process management, making it easier for developers to write concurrent code.\n",
    "#   - Libraries like Pythonâ€™s `concurrent.futures.ProcessPoolExecutor` or `multiprocessing.Pool` provide convenient interfaces for creating and managing process pools.\n",
    "\n",
    "#5. **Error Handling**:\n",
    "#   - The process pool framework typically includes built-in mechanisms for handling errors and exceptions that may occur during task execution.\n",
    "#   - This makes it easier to manage failures without crashing the entire application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd0c96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explain what multiprocessing is and why it is used in Python programs.\n",
    "\n",
    "# Multiprocessing is a programming technique that allows the simultaneous execution of multiple processes, enabling parallel execution of tasks in order to improve performance and responsiveness.\n",
    "# In Python, the `multiprocessing` module provides a way to create and manage processes, leveraging multiple CPU cores to perform tasks concurrently. \n",
    "\n",
    "# Why Use Multiprocessing in Python?\n",
    "\n",
    "# 1. **Overcoming the GIL**:\n",
    "#    - Python has a Global Interpreter Lock (GIL) that prevents multiple native threads from executing Python bytecode simultaneously. This can be a bottleneck for CPU-bound tasks.\n",
    "#    - Multiprocessing avoids this issue by creating separate processes that have their own GIL, allowing true parallel execution.\n",
    "\n",
    "# 2. **Improved Performance**:\n",
    "#    - By distributing tasks across multiple processes, programs can execute faster, especially when dealing with large datasets or computationally intensive tasks. \n",
    "#    - Each process can run on a different CPU core, leading to better CPU utilization.\n",
    "\n",
    "# 3. **Isolation**:\n",
    "#   - Processes are isolated from each other, which enhances stability and reliability. \n",
    "#   - If one process crashes, it does not affect the execution of other processes. \n",
    "#   - This isolation also helps prevent issues related to shared state, which can be problematic in multithreaded applications.\n",
    "\n",
    "# 4. **Simplified Code Structure**:\n",
    "#   - Multiprocessing can simplify the structure of certain types of applications. \n",
    "#   - For example, it allows developers to divide a large problem into smaller, independent tasks that can be executed concurrently, making code easier to manage and maintain.\n",
    "\n",
    "# 5. **Task Distribution**:\n",
    "#   - The `multiprocessing` module provides convenient methods for distributing tasks, such as `Pool`, which allows for easy mapping of functions to input data across multiple processes.\n",
    "#   - This can make parallel processing more accessible and intuitive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc74263d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: 90, List: [90]\n",
      "Removed: 90, List: []\n",
      "List is empty, cannot remove.\n",
      "List is empty, cannot remove.\n",
      "Added: 15, List: [15]\n",
      "Removed: 15, List: []\n",
      "Added: 61, List: [61]\n",
      "Added: 49, List: [61, 49]\n",
      "Removed: 61, List: [49]\n",
      "Added: 79, List: [49, 79]\n",
      "Added: 34, List: [49, 79, 34]\n",
      "Removed: 49, List: [79, 34]\n",
      "Added: 80, List: [79, 34, 80]\n",
      "Removed: 79, List: [34, 80]\n",
      "Removed: 34, List: [80]\n",
      "Added: 14, List: [80, 14]\n",
      "Removed: 80, List: [14]\n",
      "Added: 2, List: [14, 2]\n",
      "Removed: 14, List: [2]\n",
      "Added: 59, List: [2, 59]\n",
      "Final List: [2, 59]\n"
     ]
    }
   ],
   "source": [
    "## Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading lock.\n",
    "\n",
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Shared list\n",
    "shared_list = []\n",
    "# Create a lock object\n",
    "lock = threading.Lock()\n",
    "\n",
    "def add_numbers():\n",
    "    \"\"\"Function to add numbers to the shared list.\"\"\"\n",
    "    for _ in range(10):\n",
    "        num = random.randint(1, 100)\n",
    "        with lock:  # Acquire the lock before modifying the list\n",
    "            shared_list.append(num)\n",
    "            print(f\"Added: {num}, List: {shared_list}\")\n",
    "        time.sleep(random.uniform(0.1, 0.5))  # Simulate some delay\n",
    "\n",
    "def remove_numbers():\n",
    "    \"\"\"Function to remove numbers from the shared list.\"\"\"\n",
    "    for _ in range(10):\n",
    "        with lock:  # Acquire the lock before modifying the list\n",
    "            if shared_list:\n",
    "                num = shared_list.pop(0)\n",
    "                print(f\"Removed: {num}, List: {shared_list}\")\n",
    "            else:\n",
    "                print(\"List is empty, cannot remove.\")\n",
    "        time.sleep(random.uniform(0.1, 0.5))  # Simulate some delay\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create threads for adding and removing numbers\n",
    "    thread_add = threading.Thread(target=add_numbers)\n",
    "    thread_remove = threading.Thread(target=remove_numbers)\n",
    "\n",
    "    # Start the threads\n",
    "    thread_add.start()\n",
    "    thread_remove.start()\n",
    "\n",
    "    # Wait for both threads to finish\n",
    "    thread_add.join()\n",
    "    thread_remove.join()\n",
    "\n",
    "    print(\"Final List:\", shared_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d45b44ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Describe the methods and tools available in Python for safely sharing data between threads and processes.\n",
    "\n",
    "# In Python, safe data sharing between threads and processes can be achieved using various methods and tools. Hereâ€™s a detailed overview:\n",
    "\n",
    "# 1. **Threading**\n",
    "\n",
    "# a. Locks\n",
    "# - **Description**: A lock is a synchronization primitive that is used to ensure that only one thread can access a resource at a time. \n",
    "# - **Usage**: Use the `threading.Lock()` class to create a lock.\n",
    "# - **Example**:\n",
    "    \n",
    "#    import threading\n",
    "#    lock = threading.Lock()\n",
    "#    with lock:\n",
    "\n",
    "# b. RLocks (Reentrant Locks)\n",
    "# - **Description**: An `RLock` is a lock that can be acquired multiple times by the same thread without blocking itself.\n",
    "# - **Usage**: Useful in situations where the same thread might need to enter a locked section multiple times.\n",
    "# - **Example**:\n",
    "    \n",
    "#    rlock = threading.RLock()\n",
    "#    with rlock:\n",
    "\n",
    "# c. Semaphores\n",
    "# - **Description**: Semaphores manage access to a resource pool. They maintain a counter to track how many threads can access a resource at the same time.\n",
    "# - **Usage**: Useful for limiting the number of concurrent threads.\n",
    "# - **Example**:\n",
    "    \n",
    "#    semaphore = threading.Semaphore(3)  # Allow up to 3 threads\n",
    "#    with semaphore:\n",
    "      \n",
    "# d. Condition Variables\n",
    "# - **Description**: Condition variables are used for signaling between threads. They allow threads to wait until a certain condition is met.\n",
    "# - **Usage**: Used in producer-consumer problems.\n",
    "# - **Example**:\n",
    "\n",
    "#    condition = threading.Condition()\n",
    "#    with condition:\n",
    "#        condition.wait()  # Wait for a signal\n",
    "\n",
    "# 2. **Multiprocessing**\n",
    "\n",
    "# a. Queues\n",
    "# - **Description**: Queues provide a safe way for processes to exchange data. Data can be put into the queue from one process and taken out by another.\n",
    "# - **Usage**: Use `multiprocessing.Queue()`.\n",
    "# - **Example**:\n",
    "    \n",
    "#    from multiprocessing import Queue\n",
    "#    queue = Queue()\n",
    "#    queue.put(data)  # Add data to the queue\n",
    "#    item = queue.get()  # Retrieve data from the queue\n",
    "\n",
    "# b. Pipes\n",
    "# - **Description**: Pipes allow two processes to communicate with each other. They can be used for sending data back and forth.\n",
    "# - **Usage**: Use `multiprocessing.Pipe()`.\n",
    "# - **Example**:\n",
    "    \n",
    "#    from multiprocessing import Pipe\n",
    "#    parent_conn, child_conn = Pipe()\n",
    "#    child_conn.send(data)  # Send data from child to parent\n",
    "#    received_data = parent_conn.recv()  # Receive data in the parent\n",
    "\n",
    "# c. Shared Memory\n",
    "# - **Description**: Shared memory allows multiple processes to access the same data in memory, eliminating the need for data copying.\n",
    "# - **Usage**: Use `multiprocessing.Array` or `multiprocessing.Value` for creating shared memory variables.\n",
    "# - **Example**:\n",
    "    \n",
    "#    from multiprocessing import Array\n",
    "#    shared_array = Array('i', range(10))  # Create a shared array of integers\n",
    "\n",
    "# 3. **Thread- and Process-Safe Data Structures**\n",
    "#    Python's `queue.Queue` is a thread-safe data structure that can be used for inter-thread communication.\n",
    "#    Similarly, the `multiprocessing.Queue` can be used for process communication.\n",
    "\n",
    "# 4. **Global Interpreter Lock (GIL)**\n",
    "#   - **Note**: Python has a Global Interpreter Lock (GIL) which makes threads execute one at a time in CPython, the standard Python implementation. \n",
    "#   -  This means that while threads can share data easily, they are not ideal for CPU-bound tasks. Multiprocessing is generally preferred for CPU-bound operations because it bypasses the GIL by using separate memory spaces.\n",
    "\n",
    "# 5. **Third-Party Libraries**\n",
    "#   - Libraries like `concurrent.futures` provide higher-level abstractions for concurrent execution using threads and processes, making it easier to manage tasks and data sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "040ee0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Discuss why itâ€™s crucial to handle exceptions in concurrent programs and the techniques available for doing so.\n",
    "\n",
    "# Handling exceptions in concurrent programs is crucial for several reasons, as the complexity of concurrency can introduce unique challenges that must be managed effectively to maintain program stability, integrity, and reliability. Hereâ€™s a detailed discussion on why exception handling is important in concurrent programming and the techniques available for managing exceptions.\n",
    "\n",
    "# Importance of Exception Handling in Concurrent Programs\n",
    "\n",
    "# 1.Unexpected Behavior: Concurrent programs involve multiple threads or processes that run simultaneously. An unhandled exception in one thread can lead to unpredictable behavior across the entire application, potentially corrupting shared data or causing other threads to malfunction.\n",
    "# 2.Resource Management: Concurrency often involves managing resources such as file handles, network connections, and memory. Unhandled exceptions can result in resource leaks (e.g., not releasing locks or closing files), which can degrade performance or crash the program.\n",
    "# 3.Debugging Complexity: Identifying the source of an error in a concurrent program can be challenging due to the non-linear execution flow. Proper exception handling can simplify debugging by providing clear error messages and stack traces.\n",
    "# 4.Maintaining Data Integrity: When exceptions occur, the program may leave shared resources in an inconsistent state. Properly handling exceptions ensures that any necessary cleanup is performed and that data remains valid.\n",
    "# 5.User Experience: For applications with user interfaces, unhandled exceptions can lead to crashes that negatively impact user experience. Gracefully handling exceptions allows for user-friendly error messages and possible recovery options.\n",
    "\n",
    "# Techniques for Handling Exceptions in Concurrent Programs\n",
    "\n",
    "# 1. **Try-Except Blocks**:\n",
    "#   - In Python, use `try-except` blocks within threads or processes to catch exceptions and handle them gracefully. Each thread should manage its own exceptions to prevent failures from propagating.\n",
    "   \n",
    "#   import threading\n",
    "\n",
    "#   def thread_function():\n",
    "#       try:\n",
    "           # Code that may raise an exception\n",
    "#           pass\n",
    "#       except Exception as e:\n",
    "#           print(f\"Error in thread: {e}\")\n",
    "#   thread = threading.Thread(target=thread_function)\n",
    "#   thread.start()\n",
    "\n",
    "# 2. **Using Futures and Callbacks**:\n",
    "#    - With libraries like `concurrent.futures`, you can submit tasks and handle exceptions using the `Future` object. This allows for centralized exception handling.\n",
    "#   from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "#   def task():\n",
    "#       raise ValueError(\"An error occurred!\")\n",
    "\n",
    "#   with ThreadPoolExecutor() as executor:\n",
    "#       future = executor.submit(task)\n",
    "#       try:\n",
    "#           result = future.result()  # This will raise the exception\n",
    "#       except Exception as e:\n",
    "#           print(f\"Caught an exception: {e}\")\n",
    "\n",
    "# 3. **Logging**:\n",
    "#   - Implement logging within exception handlers to keep track of errors. This is especially useful for debugging and monitoring in production environments.\n",
    "   \n",
    "#   import logging\n",
    "#   logging.basicConfig(level=logging.ERROR)\n",
    "#   def thread_function():\n",
    "#       try:\n",
    "           # Code that may raise an exception\n",
    "#           pass\n",
    "#       except Exception as e:\n",
    "#           logging.error(f\"Error in thread: {e}\")\n",
    "\n",
    "# 4. **Custom Exception Classes**:\n",
    "#   - Define custom exception classes for specific error conditions in concurrent programs, which can help to identify and handle different types of exceptions more effectively.\n",
    "\n",
    "# 5. **Graceful Shutdown**:\n",
    "#   - Implement mechanisms to gracefully shut down threads or processes upon encountering exceptions. This can include setting flags to signal threads to stop, ensuring resources are cleaned up properly.\n",
    "#   import threading\n",
    "#   stop_event = threading.Event()\n",
    "\n",
    "#   def thread_function():\n",
    "#       try:\n",
    "#           while not stop_event.is_set():\n",
    "               # Thread work\n",
    "#               pass\n",
    "#       except Exception as e:\n",
    "#           print(f\"Error in thread: {e}\")\n",
    "#           stop_event.set()  # Signal to stop on error\n",
    "\n",
    "# 6. **Using Context Managers**:\n",
    "#    - For managing resources such as file handles or network connections, use context managers (`with` statement) to ensure that resources are properly released even when exceptions occur.\n",
    "\n",
    "# 7. **Testing and Code Reviews**:\n",
    "#   - Regular testing and code reviews can help identify potential areas where exceptions may not be handled properly, ensuring more robust concurrent code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a021aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorial of 1 is 1\n",
      "Factorial of 2 is 2\n",
      "Factorial of 3 is 6\n",
      "Factorial of 4 is 24\n",
      "Factorial of 5 is 120\n",
      "Factorial of 6 is 720\n",
      "Factorial of 7 is 5040\n",
      "Factorial of 8 is 40320\n",
      "Factorial of 9 is 362880\n",
      "Factorial of 10 is 3628800\n"
     ]
    }
   ],
   "source": [
    "## Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
    "\n",
    "import concurrent.futures\n",
    "import math\n",
    "\n",
    "def calculate_factorial(n):\n",
    "    \"\"\"Function to calculate the factorial of a number.\"\"\"\n",
    "    return math.factorial(n)\n",
    "\n",
    "def main():\n",
    "    numbers = range(1, 11)  # Numbers from 1 to 10\n",
    "\n",
    "    # Using ThreadPoolExecutor to manage threads\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Map the calculate_factorial function to the numbers\n",
    "        results = list(executor.map(calculate_factorial, numbers))\n",
    "    \n",
    "    # Print the results\n",
    "    for num, factorial in zip(numbers, results):\n",
    "        print(f\"Factorial of {num} is {factorial}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21ea3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8processes)\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def compute_square(n):\n",
    "    return n * n\n",
    "\n",
    "def main():\n",
    "    numbers = range(1, 11)  # Numbers from 1 to 10\n",
    "    pool_sizes = [2, 4, 8]  # Different pool sizes\n",
    "\n",
    "    for pool_size in pool_sizes:\n",
    "        # Measure the time taken for each pool size\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Create a pool of worker processes\n",
    "        with multiprocessing.Pool(processes=pool_size) as pool:\n",
    "            results = pool.map(compute_square, numbers)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        # Print results and time taken\n",
    "        print(f\"Pool size: {pool_size}, Results: {results}, Time taken: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd654dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
